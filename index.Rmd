---
title: "Computational Musicology"
author: "Tessa Vermeulen"
date: 'March 2022'
output:
  flexdashboard::flex_dashboard:
    css: styles.css
    self_contained: false
    orientation: columns
    theme: cerulean
    
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, libraries, include=FALSE}
library(tidyverse)
library(plyr)
library(dplyr)
library(spotifyr)
library(plotly)
library(compmus)
library(lubridate)
library(ggplot2)
library(tidymodels)
library(protoclust)
library(heatmaply)
library(scales)
library(gridExtra)
library(grid)
library(readxl)
library(ggdendro)


```



Sprinters vs Long-distance swimmers {data-icon="fa-info-circle"}
=========================================
Column {data-width=600}
------------------------------------

#### Introduction
Let me introduce myself. My name is Tessa, and I am a professional athlete. I swim in the national team and have won several national and international medals. 

During competitions I listen to music that inspires and motivates me. So, for me and a lot of my team mates, music plays an important role in the optimal race preperation. 

In swimming there are different diciplines. More specificly there are sprinters, and long-distance swimmers. Sprinters exert maximum effort for a short period of time, often no longer than 30 seconds. A long-distance swimmer does not have to be so explosive, and the exertion of their race usually lasts more than two minutes. 

Of course not all swimmers lissten to music during their preperantion, but in my experience there are both sprinters and long-distance swimmers who have special playlists for competitions. 


#### Research question

Since sprinters and long distance differ so much from each other in terms of performances, the research question I will try to answer in this portfolio is: 

**What are the differences between the motivation playlists of sprinters and long-distance swimmers?**

First we look at the track level Spotify features of both playlists. Are there for example differences in energy, or tempo? I expect that the sprinter playlist contains more songs with higher energy and tempo. 

#### Playlists 

For this portfolio, I used several playlists of my teammates. I have subdivided these playlists in two groups, namely a playlist with tracks that sprinters listen to and one that long-distance swimmers listen to. 

**Typical tracks for sprinters:**

* "Thunderstruck" from AC/DC
* "Let's do this" from Outskrts

**Typical tracks for long-distance swimmers:**

* "Nothing else matters" from Metallica
* "Eye of the tiger" from Rocky IV


Column {data-width=400}
------------------------------------
test 

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/0Wik64zBKFTNoNjTpG70OH?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>


Analysis {.storyboard data-icon="fa-chart-bar"}
============================================

### First lets look at the __genres__ of each playlist

```{r, genres, echo=FALSE}
df_long = read_excel('genre_count_long.xlsx')
df_sprint = read_excel('genre_count_sprint.xlsx')

both_genres <-
  bind_rows(
    df_long %>% mutate(category = "Long-distance playlist"),
    df_sprint %>% mutate(category = "Sprinters playlist")
  )

genre_histogram <- both_genres %>%
  ggplot(aes(x=Count, y = Genre)) +
  geom_col(fill="#295590", alpha=0.75) +
  geom_text(aes(label = Percentage)) +
  xlim(0,30) +
  theme_classic() +
  facet_wrap(~category)
  

ggplotly(genre_histogram)
```
***
#### Main genres
As you can see, there is a clear difference between the two playlists. The long-distance playlist contains mostly pop songs, unlike the sprinters playlist, which mainly consists of rock songs.

This could be an interesting feature that we will further explore in the next sections. 


### Changes in __energy__ and __danceability__ point out the differences between sprinters and long-distance swimmers
```{r, energy, echo=FALSE}
long_distance <- get_playlist_audio_features("","56vEaKq9VqFBlqtcXZAgn4")
sprinters <- get_playlist_audio_features("", "70wUKUusJoxhLNieGGRXpK")


total <-
  bind_rows(
    long_distance %>% mutate(Category = "Long-distance playlist"),
    sprinters %>% mutate(Category = "Sprinters playlist")
  )

e <- ggplot(total, aes(Category, energy)) + 
  geom_boxplot()

#ggplotly(e, tooltip = c("category"))

d <- ggplot(total, aes(Category, danceability)) + 
  geom_boxplot()
#ggplotly(d, tooltip = c("category"))

grid.arrange(e, d, ncol=2)
#ggplotly(plot)

```

***
As the plots show, sprinters listen to music with higher energy, and the songs of long-distance swimmers have higher danceability. One outlier in energy is the song "Nothing else matters" from Metallica. This song is ... lower in energy than them mean of the long-distance playlist. 
A reason for this could be that people listen to this song because they want to control their nerves before the race and don't want to listen to a very energetic song. Another reason that this song is in this playlist, is that lyrics of the song is also an important factor.

### Can we say something about the __keys__ of the different playlists?

```{r, key_hist, echo=FALSE}
long_distance <- get_playlist_audio_features("","56vEaKq9VqFBlqtcXZAgn4")
sprinters <- get_playlist_audio_features("", "70wUKUusJoxhLNieGGRXpK")


total <-
  bind_rows(
    long_distance %>% mutate(category = "Long-distance playlist"),
    sprinters %>% mutate(category = "Sprinters playlist")
  )

key_histogram <- total %>%
  ggplot(aes(x=key, fill=category)) +
  geom_bar(position = 'dodge', binwidth = 0.55) +
  labs(title = "Key histogram") +
  scale_fill_manual(values = c('#93B9D0', '#295590'), guide = "none") +
  theme_classic()

ggplotly(key_histogram)
```

*** 
The histogram of the keys shows what keys are used in the different playlists. As we can see, the majority of the tracks of the sprinters playlist ar in key 1 (C#/Db). This corresponds to the fact that the sprinters playlist mainly contains rock songs. For the long distance playlist, the distribution is more spread out. 


### Diving deeper into "Nothing else matters": a __keygram__
```{r, keygram, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )


nothing_else_matters <-
  get_tidy_audio_analysis("0nLiqZ6A27jJri2VCalIUs") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

#keygram
nothing_else_matters %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "Time (s)", y = "")

```

***
The song Nothing else matters was the song with the lowest energy. So lets take a closer look at this song. 
A keygram of a song compares  the keys of a song to a particular key template, to figure out the key of a song. When we look at the plot, the x-axis shows the time and duration of the song, and the y-axis shows the different possible keys. A dark color in the plot means that key matches the key in the template. If the color gets lighter, there isn't a key that matches a particular key template. 

So at the beginning of the song, and towards the end, there are no good matches. However, around time 100s we can see a very dark color for the E:min chord, so chances are that this chord matches the template at this time in the song. 

The song is in e minor 




Classification {.storyboard data-icon="fa-chart-bar"}
============================================

### An important aspect of classification is __feature selection__. So lets have a look at what features are most important. 

```{r, features, echo=FALSE}

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  


sprint <- get_playlist_audio_features("spotify", "70wUKUusJoxhLNieGGRXpK")
ld <- get_playlist_audio_features("spotify", "56vEaKq9VqFBlqtcXZAgn4")
wedstrijd <-
  bind_rows(
    sprint %>% mutate(playlist = "Sprinters playlist"),
    ld %>% mutate(playlist = "Long-distance playlist")
  ) 

wedstrijd_features <-
  wedstrijd %>%  # For your portfolio, change this to the name of your corpus.
  add_audio_analysis() %>% 
  mutate(
    playlist = factor(playlist),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))


wedstrijd_recipe <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 +
      c02 +
      c03 +
      c04 + c05 + 
      c06 +
      c07 + 
      c08 + 
      c09 + c10 + 
      c11 + 
      c12,
    data = wedstrijd_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
# step_range(all_predictors())    # Sets range to [0, 1].


wedstrijd_cv <- wedstrijd_features %>% vfold_cv(5)

forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")
wedstrijd_forest <- 
  workflow() %>% 
  add_recipe(wedstrijd_recipe) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    wedstrijd_cv, 
    control = control_resamples(save_pred = TRUE)
  )


workflow() %>% 
  add_recipe(wedstrijd_recipe) %>% 
  add_model(forest_model) %>% 
  fit(wedstrijd_features) %>% 
  pluck("fit", "fit", "fit") %>%
  ranger::importance() %>% 
  enframe() %>% 
  mutate(name = fct_reorder(name, value)) %>% 
  ggplot(aes(name, value)) + 
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Importance")


```

*** 

If we look at the plot, we can see that _energy_,  _danceability_ and the _second timbre coefficient_ are the most important features. This corresponds to our first expectations. In the analysis of the different spotify features, we could see that there was a big difference in energy and danceability between the two playlists. Duration and liveness are the least important features. 


### Now we use random forest to make classifications. During training and testing, all features are initially included. 


```{r, random_forest, echo=FALSE}
wedstrijd_forest %>% get_conf_mat() %>% autoplot(type = "heatmap")
wedstrijd_forest %>% get_pr()

```

*** 

Classification with random forest gives a precision of ... on the sprinters playlist, and .... precision on the long-distance playlist. If we look at the heatmap, we can see that ... of the songs in the sprinters playlist were not correctly classified as a song from the long-distance playlist. ... songs were not correctly classified from the long-distance playlist. 
Looking at which songs were not correctly classified might help us get a clearer view of why this was the case. 
- to do: taking a closer look at the songs.


### Can we improve our model? We now use the top 6 most important features for classification. 

```{r, random_features, echo=FALSE}
wedstrijd_recipe <-
  recipe(
    playlist ~
      danceability +
      energy +
      acousticness +
      tempo +
      c02 +
      c06 +
      c11, 
    data = wedstrijd_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
# step_range(all_predictors())    # Sets range to [0, 1].


wedstrijd_cv <- wedstrijd_features %>% vfold_cv(5)


forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")
wedstrijd_forest <- 
  workflow() %>% 
  add_recipe(wedstrijd_recipe) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    wedstrijd_cv, 
    control = control_resamples(save_pred = TRUE)
  )

wedstrijd_forest %>% get_conf_mat() %>% autoplot(type = "heatmap")

```
```{r}
wedstrijd_forest %>% get_pr()
```

***

After feature selection, the model did not improve significantly. Now the precision of the sprinters playlist is 0.83 and the precision of the long-distance playlist is 0.85. 
- to do: beter uitleggen hoe dit kan 
- nog verder proberen te verbeteren. 



Conclusion {data-icon="fa-info-circle"}
=========================================

still working on conclusion 
- to do: plots en precision recall mooi weergeven
- alle overige plots in de analyse zetten
- overal een goede uitleg geven 










